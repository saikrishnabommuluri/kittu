{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found the Data folder where the different bank transactions formats are found\n",
      "hi\n",
      "['bank1.csv', 'bank2.csv', 'bank3.csv']\n",
      "   amount  amounts  cents        date date_readable    euro  from   timestamp  \\\n",
      "0    99.2      NaN    NaN         NaN           NaN     NaN   198  Oct 1 2019   \n",
      "1  2000.1      NaN    NaN         NaN           NaN     NaN   188  Oct 2 2019   \n",
      "0     NaN     99.4    NaN  03-10-2019           NaN     NaN   198         NaN   \n",
      "1     NaN   2123.5    NaN  04-10-2019           NaN     NaN   188         NaN   \n",
      "0     NaN      NaN    7.0         NaN    5 Oct 2019     5.0   198         NaN   \n",
      "1     NaN      NaN    8.0         NaN    6 Oct 2019  1060.0   188         NaN   \n",
      "\n",
      "    to transaction    type  \n",
      "0  182         NaN  remove  \n",
      "1  198         NaN     add  \n",
      "0  182      remove     NaN  \n",
      "1  198         add     NaN  \n",
      "0  182         NaN  remove  \n",
      "1  198         NaN     add  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SubrahmanyaSaiKrishn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing the Necessary Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#Function to convert any dataframe into XML format\n",
    "def to_xml(df):\n",
    "    def row_xml(row):\n",
    "        xml = ['<item>']\n",
    "        for i, col_name in enumerate(row.index):\n",
    "            xml.append('  <{0}>{1}</{0}>'.format(col_name, row.iloc[i]))\n",
    "        xml.append('</item>')\n",
    "        return '\\n'.join(xml)\n",
    "    res = '\\n'.join(df.apply(row_xml, axis=1))\n",
    "    return(res)\n",
    "1\n",
    "\n",
    "#Function to merge all the csv files present in the data folder into 1 csv/xm/json file.\n",
    "def process_extracts(path):\n",
    "    csv_directory = os.listdir(path)\n",
    "    f = []\n",
    "    # To get the names and paths of all the files present in the data Folder\n",
    "    for i in csv_directory:\n",
    "        final_path = path + '\\\\' + i\n",
    "        f.append(final_path)\n",
    "    #Combining different csv files into a single dataFrame\n",
    "    combined_csv_data = pd.concat([pd.read_csv(f) for f in f])\n",
    "    \n",
    "    #Generating the finalised csv file\n",
    "    combined_csv_data.to_csv('Final_csv')\n",
    "    \n",
    "    # Genrating the finalised XML file\n",
    "    with open('Final.XML', 'w') as f:\n",
    "         f.write(to_xml(combined_csv_data))\n",
    "            \n",
    "    # Generating the finalised json file\n",
    "    combined_csv_data.to_json('Final.json',orient='table')\n",
    "    \n",
    "        \n",
    "#Defining the required variables and dataframes     \n",
    "combined_csv_data = pd.DataFrame()\n",
    "str = ''\n",
    "#To get the current path\n",
    "c = os.getcwd()\n",
    "l = os.listdir(c)\n",
    "count = 0\n",
    "if 'Data' in l:\n",
    "    count = 1\n",
    "    str = l\n",
    "else:\n",
    "    a = list(c.split('\\\\'))\n",
    "    b = a[:len(a)-1]\n",
    "    str = \"\\\\\".join(b)\n",
    "    l = os.listdir(str)\n",
    "    if 'Data' not in l:\n",
    "        print(\"No Data folder forund which means none of the bank data we have received\")\n",
    "    else:\n",
    "        count = 1\n",
    "if count == 1:\n",
    "    print(\"We have found the Data folder where the different bank transactions formats are found\")\n",
    "    str1 = str + '\\\\' + 'Data'\n",
    "    m = os.listdir(str1)\n",
    "    #To check if the data folder really contains any csv files\n",
    "    if not m:\n",
    "        print(\"There are no bank extracts in the data folder. SO we cannot generate a finalised csv now\")\n",
    "    else:\n",
    "        process_extracts(str1)\n",
    "\n",
    "\n",
    "if __name__ == __main__:\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found the Data folder where the different banks related data is usually available\n",
      "We Have found 3 extracts in the data folder. We are about to generate a single extract\n",
      "These are the extracts present in the Data Folder:\n",
      "bank1.csv \n",
      "\n",
      "bank2.csv \n",
      "\n",
      "bank3.csv \n",
      "\n",
      "Finally generated the combination of the above files as unified file of csv,xml and json with names as  Final.csv, Final.XML and Final.json files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SubrahmanyaSaiKrishn\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "#Function to convert any dataframe into XML format\n",
    "def to_xml(df):\n",
    "    def row_xml(row):\n",
    "        xml = ['<item>']\n",
    "        for i, col_name in enumerate(row.index):\n",
    "            xml.append('  <{0}>{1}</{0}>'.format(col_name, row.iloc[i]))\n",
    "        xml.append('</item>')\n",
    "        return '\\n'.join(xml)\n",
    "    res = '\\n'.join(df.apply(row_xml, axis=1))\n",
    "    return(res)\n",
    "1\n",
    "\n",
    "#Function to merge all the csv files present in the data folder into 1 csv/XML/json file.\n",
    "def process_extracts(path):\n",
    "    csv_directory = os.listdir(path)\n",
    "    f = []\n",
    "    # To get the names and paths of all the files present in the data Folder\n",
    "    print(\"These are the extracts present in the Data Folder:\")\n",
    "    for i in csv_directory:\n",
    "        final_path = path + '\\\\' + i\n",
    "        f.append(final_path)\n",
    "        print(i,'\\n')\n",
    "    \n",
    "    \n",
    "    #Combining different csv files into a single dataFrame\n",
    "    combined_csv_data = pd.concat([pd.read_csv(f) for f in f])\n",
    "    \n",
    "    #Generating the finalised csv file\n",
    "    combined_csv_data.to_csv('Final_csv')\n",
    "    \n",
    "    # Genrating the finalised XML file\n",
    "    with open('Final.XML', 'w') as f:\n",
    "         f.write(to_xml(combined_csv_data))\n",
    "            \n",
    "    # Generating the finalised json file\n",
    "    combined_csv_data.to_json('Final.json',orient='table')\n",
    "    print('Finally generated the combination of the above files as unified file of csv,xml and json with names as  Final.csv, Final.XML and Final.json files')\n",
    "\n",
    "\n",
    "def source():\n",
    "    #Defining the required variables and dataframes     \n",
    "    combined_csv_data = pd.DataFrame()\n",
    "    str = ''\n",
    "    #To get the current path\n",
    "    c = os.getcwd()\n",
    "    l = os.listdir(c)\n",
    "    count = 0\n",
    "    if 'Data' in l:\n",
    "        count = 1\n",
    "        str = l\n",
    "    else:\n",
    "        a = list(c.split('\\\\'))\n",
    "        b = a[:len(a)-1]\n",
    "        str = \"\\\\\".join(b)\n",
    "        l = os.listdir(str)\n",
    "        if 'Data' not in l:\n",
    "            print(\"No Data folder forund which means none of the bank data we have received\")\n",
    "        else:\n",
    "            count = 1\n",
    "    if count == 1:\n",
    "        print(\"We have found the Data folder where the different banks related data is usually available\")\n",
    "        str1 = str + '\\\\' + 'Data'\n",
    "        m = os.listdir(str1)\n",
    "    #To check if the data folder really contains any csv files\n",
    "        if not m:\n",
    "           print(\"There are no bank extracts in the data folder. So, we cannot generate a finalised csv now\")\n",
    "        else:\n",
    "           n = len(m)\n",
    "           print(f'We Have found {n} extracts in the data folder. We are about to generate a single extract')\n",
    "           process_extracts(str1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Calling the main source function\n",
    "    source()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
